{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyforest\n",
    "\n",
    "# data processing library\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# machine learning library\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier \n",
    "\n",
    "#evaluation library\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visulization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(14,6)})\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.481386e+04</td>\n",
       "      <td>47488.145955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54201.500000</td>\n",
       "      <td>84692.000000</td>\n",
       "      <td>139320.500000</td>\n",
       "      <td>172792.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>1.958696</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-0.920373</td>\n",
       "      <td>0.018109</td>\n",
       "      <td>1.315642</td>\n",
       "      <td>2.454930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>1.651309</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-0.598550</td>\n",
       "      <td>0.065486</td>\n",
       "      <td>0.803724</td>\n",
       "      <td>22.057729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>1.516255</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>-0.890365</td>\n",
       "      <td>0.179846</td>\n",
       "      <td>1.027196</td>\n",
       "      <td>9.382558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>1.415869</td>\n",
       "      <td>-5.683171</td>\n",
       "      <td>-0.848640</td>\n",
       "      <td>-0.019847</td>\n",
       "      <td>0.743341</td>\n",
       "      <td>16.875344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>1.380247</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>-0.691597</td>\n",
       "      <td>-0.054336</td>\n",
       "      <td>0.611926</td>\n",
       "      <td>34.801666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>1.332271</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-0.768296</td>\n",
       "      <td>-0.274187</td>\n",
       "      <td>0.398565</td>\n",
       "      <td>73.301626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>1.237094</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-0.554076</td>\n",
       "      <td>0.040103</td>\n",
       "      <td>0.570436</td>\n",
       "      <td>120.589494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>1.194353</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-0.208630</td>\n",
       "      <td>0.022358</td>\n",
       "      <td>0.327346</td>\n",
       "      <td>20.007208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>1.098632</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>-0.643098</td>\n",
       "      <td>-0.051429</td>\n",
       "      <td>0.597139</td>\n",
       "      <td>15.594995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.768627e-15</td>\n",
       "      <td>1.088850</td>\n",
       "      <td>-24.588262</td>\n",
       "      <td>-0.535426</td>\n",
       "      <td>-0.092917</td>\n",
       "      <td>0.453923</td>\n",
       "      <td>23.745136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.170318e-16</td>\n",
       "      <td>1.020713</td>\n",
       "      <td>-4.797473</td>\n",
       "      <td>-0.762494</td>\n",
       "      <td>-0.032757</td>\n",
       "      <td>0.739593</td>\n",
       "      <td>12.018913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.810658e-15</td>\n",
       "      <td>0.999201</td>\n",
       "      <td>-18.683715</td>\n",
       "      <td>-0.405571</td>\n",
       "      <td>0.140033</td>\n",
       "      <td>0.618238</td>\n",
       "      <td>7.848392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.693438e-15</td>\n",
       "      <td>0.995274</td>\n",
       "      <td>-5.791881</td>\n",
       "      <td>-0.648539</td>\n",
       "      <td>-0.013568</td>\n",
       "      <td>0.662505</td>\n",
       "      <td>7.126883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.479045e-15</td>\n",
       "      <td>0.958596</td>\n",
       "      <td>-19.214325</td>\n",
       "      <td>-0.425574</td>\n",
       "      <td>0.050601</td>\n",
       "      <td>0.493150</td>\n",
       "      <td>10.526766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>3.482336e-15</td>\n",
       "      <td>0.915316</td>\n",
       "      <td>-4.498945</td>\n",
       "      <td>-0.582884</td>\n",
       "      <td>0.048072</td>\n",
       "      <td>0.648821</td>\n",
       "      <td>8.877742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.392007e-15</td>\n",
       "      <td>0.876253</td>\n",
       "      <td>-14.129855</td>\n",
       "      <td>-0.468037</td>\n",
       "      <td>0.066413</td>\n",
       "      <td>0.523296</td>\n",
       "      <td>17.315112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-7.528491e-16</td>\n",
       "      <td>0.849337</td>\n",
       "      <td>-25.162799</td>\n",
       "      <td>-0.483748</td>\n",
       "      <td>-0.065676</td>\n",
       "      <td>0.399675</td>\n",
       "      <td>9.253526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>4.328772e-16</td>\n",
       "      <td>0.838176</td>\n",
       "      <td>-9.498746</td>\n",
       "      <td>-0.498850</td>\n",
       "      <td>-0.003636</td>\n",
       "      <td>0.500807</td>\n",
       "      <td>5.041069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.049732e-16</td>\n",
       "      <td>0.814041</td>\n",
       "      <td>-7.213527</td>\n",
       "      <td>-0.456299</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.458949</td>\n",
       "      <td>5.591971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>5.085503e-16</td>\n",
       "      <td>0.770925</td>\n",
       "      <td>-54.497720</td>\n",
       "      <td>-0.211721</td>\n",
       "      <td>-0.062481</td>\n",
       "      <td>0.133041</td>\n",
       "      <td>39.420904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>0.734524</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-0.228395</td>\n",
       "      <td>-0.029450</td>\n",
       "      <td>0.186377</td>\n",
       "      <td>27.202839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>0.725702</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-0.542350</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.528554</td>\n",
       "      <td>10.503090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>0.624460</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-0.161846</td>\n",
       "      <td>-0.011193</td>\n",
       "      <td>0.147642</td>\n",
       "      <td>22.528412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>0.605647</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-0.354586</td>\n",
       "      <td>0.040976</td>\n",
       "      <td>0.439527</td>\n",
       "      <td>4.584549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>0.521278</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-0.317145</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>0.350716</td>\n",
       "      <td>7.519589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>0.482227</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-0.326984</td>\n",
       "      <td>-0.052139</td>\n",
       "      <td>0.240952</td>\n",
       "      <td>3.517346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>0.403632</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-0.070840</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.091045</td>\n",
       "      <td>31.612198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>0.330083</td>\n",
       "      <td>-15.430084</td>\n",
       "      <td>-0.052960</td>\n",
       "      <td>0.011244</td>\n",
       "      <td>0.078280</td>\n",
       "      <td>33.847808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>8.834962e+01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>25691.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.727486e-03</td>\n",
       "      <td>0.041527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count          mean           std         min           25%  \\\n",
       "Time    284807.0  9.481386e+04  47488.145955    0.000000  54201.500000   \n",
       "V1      284807.0  3.919560e-15      1.958696  -56.407510     -0.920373   \n",
       "V2      284807.0  5.688174e-16      1.651309  -72.715728     -0.598550   \n",
       "V3      284807.0 -8.769071e-15      1.516255  -48.325589     -0.890365   \n",
       "V4      284807.0  2.782312e-15      1.415869   -5.683171     -0.848640   \n",
       "V5      284807.0 -1.552563e-15      1.380247 -113.743307     -0.691597   \n",
       "V6      284807.0  2.010663e-15      1.332271  -26.160506     -0.768296   \n",
       "V7      284807.0 -1.694249e-15      1.237094  -43.557242     -0.554076   \n",
       "V8      284807.0 -1.927028e-16      1.194353  -73.216718     -0.208630   \n",
       "V9      284807.0 -3.137024e-15      1.098632  -13.434066     -0.643098   \n",
       "V10     284807.0  1.768627e-15      1.088850  -24.588262     -0.535426   \n",
       "V11     284807.0  9.170318e-16      1.020713   -4.797473     -0.762494   \n",
       "V12     284807.0 -1.810658e-15      0.999201  -18.683715     -0.405571   \n",
       "V13     284807.0  1.693438e-15      0.995274   -5.791881     -0.648539   \n",
       "V14     284807.0  1.479045e-15      0.958596  -19.214325     -0.425574   \n",
       "V15     284807.0  3.482336e-15      0.915316   -4.498945     -0.582884   \n",
       "V16     284807.0  1.392007e-15      0.876253  -14.129855     -0.468037   \n",
       "V17     284807.0 -7.528491e-16      0.849337  -25.162799     -0.483748   \n",
       "V18     284807.0  4.328772e-16      0.838176   -9.498746     -0.498850   \n",
       "V19     284807.0  9.049732e-16      0.814041   -7.213527     -0.456299   \n",
       "V20     284807.0  5.085503e-16      0.770925  -54.497720     -0.211721   \n",
       "V21     284807.0  1.537294e-16      0.734524  -34.830382     -0.228395   \n",
       "V22     284807.0  7.959909e-16      0.725702  -10.933144     -0.542350   \n",
       "V23     284807.0  5.367590e-16      0.624460  -44.807735     -0.161846   \n",
       "V24     284807.0  4.458112e-15      0.605647   -2.836627     -0.354586   \n",
       "V25     284807.0  1.453003e-15      0.521278  -10.295397     -0.317145   \n",
       "V26     284807.0  1.699104e-15      0.482227   -2.604551     -0.326984   \n",
       "V27     284807.0 -3.660161e-16      0.403632  -22.565679     -0.070840   \n",
       "V28     284807.0 -1.206049e-16      0.330083  -15.430084     -0.052960   \n",
       "Amount  284807.0  8.834962e+01    250.120109    0.000000      5.600000   \n",
       "Class   284807.0  1.727486e-03      0.041527    0.000000      0.000000   \n",
       "\n",
       "                 50%            75%            max  \n",
       "Time    84692.000000  139320.500000  172792.000000  \n",
       "V1          0.018109       1.315642       2.454930  \n",
       "V2          0.065486       0.803724      22.057729  \n",
       "V3          0.179846       1.027196       9.382558  \n",
       "V4         -0.019847       0.743341      16.875344  \n",
       "V5         -0.054336       0.611926      34.801666  \n",
       "V6         -0.274187       0.398565      73.301626  \n",
       "V7          0.040103       0.570436     120.589494  \n",
       "V8          0.022358       0.327346      20.007208  \n",
       "V9         -0.051429       0.597139      15.594995  \n",
       "V10        -0.092917       0.453923      23.745136  \n",
       "V11        -0.032757       0.739593      12.018913  \n",
       "V12         0.140033       0.618238       7.848392  \n",
       "V13        -0.013568       0.662505       7.126883  \n",
       "V14         0.050601       0.493150      10.526766  \n",
       "V15         0.048072       0.648821       8.877742  \n",
       "V16         0.066413       0.523296      17.315112  \n",
       "V17        -0.065676       0.399675       9.253526  \n",
       "V18        -0.003636       0.500807       5.041069  \n",
       "V19         0.003735       0.458949       5.591971  \n",
       "V20        -0.062481       0.133041      39.420904  \n",
       "V21        -0.029450       0.186377      27.202839  \n",
       "V22         0.006782       0.528554      10.503090  \n",
       "V23        -0.011193       0.147642      22.528412  \n",
       "V24         0.040976       0.439527       4.584549  \n",
       "V25         0.016594       0.350716       7.519589  \n",
       "V26        -0.052139       0.240952       3.517346  \n",
       "V27         0.001342       0.091045      31.612198  \n",
       "V28         0.011244       0.078280      33.847808  \n",
       "Amount     22.000000      77.165000   25691.160000  \n",
       "Class       0.000000       0.000000       1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependent Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x27ad5977460>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_transc = df[df['Class']==1]\n",
    "normal_tranc = df[df['Class']==0]\n",
    "total = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of fraud tranc 492\n",
      "no of normal tranc 284315\n"
     ]
    }
   ],
   "source": [
    "print('no of fraud tranc',len(fraud_transc))\n",
    "print('no of normal tranc',len(normal_tranc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_count = len(fraud_transc)\n",
    "non_fraud_count = len(normal_tranc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284807"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fraud_transc) + len(normal_tranc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fraud Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_percentage = ((fraud_count/non_fraud_count*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17304750013189596"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so total noumber of fraud case are 492 \n",
      "  total noumber of non fraud cases are 284315\n",
      "  percentage of fraud is 0.17304750013189596%\n"
     ]
    }
   ],
   "source": [
    "print(f'so total noumber of fraud case are {fraud_count} \\n  total noumber of non fraud cases are {non_fraud_count}\\n  percentage of fraud is {fraud_percentage}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amount column Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     492.000000\n",
       "mean      122.211321\n",
       "std       256.683288\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         9.250000\n",
       "75%       105.890000\n",
       "max      2125.870000\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_transc['Amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    284315.000000\n",
       "mean         88.291022\n",
       "std         250.105092\n",
       "min           0.000000\n",
       "25%           5.650000\n",
       "50%          22.000000\n",
       "75%          77.050000\n",
       "max       25691.160000\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_tranc['Amount'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "while seeing the the above statistics we can see that amount column is changing enormously when compared to the rest of the variables.so we need to standardized the amount column using the ‘StandardScaler’ method in python  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    149.62\n",
       "1      2.69\n",
       "2    378.66\n",
       "3    123.50\n",
       "4     69.99\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Amount'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount = df['Amount'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([149.62,   2.69, 378.66, ...,  67.88,  10.  , 217.  ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Amount'] = sc.fit_transform(amount.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.244964\n",
       "1   -0.342475\n",
       "2    1.160686\n",
       "3    0.140534\n",
       "4   -0.073403\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Amount'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now The Data is ready to split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Class', axis=1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of x_train ->227845, length of y_train ->227845 \n",
      " length of x_test ->56962, length of y_test->56962 \n"
     ]
    }
   ],
   "source": [
    "print(f'length of x_train ->{len(x_train)}, length of y_train ->{len(y_train)} \\n length of x_test ->{len(x_test)}, length of y_test->{len(y_test)} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now our data is split into train and test set and is ready for model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utkar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logr = LogisticRegression()\n",
    "logr.fit(x_train, y_train)\n",
    "logr_pred = logr.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth = 4, criterion = 'entropy')\n",
    "tree.fit(x_train, y_train)\n",
    "tree_pred = tree.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ran_forest = RandomForestClassifier(max_depth = 4)\n",
    "ran_forest.fit(x_train, y_train)\n",
    "ran_forest_pred = ran_forest.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "svc.fit(x_train, y_train)\n",
    "svc_pred = svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "knn = KNeighborsClassifier(n_neighbors = n)\n",
    "knn.fit(x_train, y_train)\n",
    "knn_pred = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X G Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utkar\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:09:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth = 4)\n",
    "xgb.fit(x_train, y_train)\n",
    "xgb_pred = xgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy score = No.of correct predictions / Total no.of predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuaracy score of logistic regression model -->0.9990695551420246\n",
      "Accuaracy score of Descision tree model -->0.9993679997191109\n",
      "Accuaracy score of Random Forest Classifier model -->0.9992977774656788\n",
      "Accuaracy score of Support Vector Classifier model -->0.9982268881008391\n",
      "Accuaracy score of KNeighborsClassifier model -->0.9983848881710614\n",
      "Accuaracy score of XGBClassifier model -->0.9995084442259752\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuaracy score of logistic regression model -->{accuracy_score(y_test, logr_pred)}')\n",
    "print(f'Accuaracy score of Descision tree model -->{accuracy_score(y_test, tree_pred)}')\n",
    "print(f'Accuaracy score of Random Forest Classifier model -->{accuracy_score(y_test, ran_forest_pred)}')\n",
    "print(f'Accuaracy score of Support Vector Classifier model -->{accuracy_score(y_test, svc_pred)}')\n",
    "print(f'Accuaracy score of KNeighborsClassifier model -->{accuracy_score(y_test, knn_pred)}')\n",
    "print(f'Accuaracy score of XGBClassifier model -->{accuracy_score(y_test,  xgb_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So we can see Decision tree has maximum accuracy rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of logistic regression model -->\n",
      "[[56831    30]\n",
      " [   23    78]]\n",
      "Confusion Matrix of Descision tree model -->\n",
      "[[56849    12]\n",
      " [   24    77]]\n",
      "Confusion Matrix of Random Forest Classifier model -->\n",
      "[[56854     7]\n",
      " [   33    68]]\n",
      "Confusion Matrix of Support Vector Classifier model -->\n",
      "[[56861     0]\n",
      " [  101     0]]\n",
      "Confusion Matrix of KNeighborsClassifier model -->\n",
      "[[56861     0]\n",
      " [   92     9]]\n",
      "Confusion Matrix of XGBClassifier model -->\n",
      "[[56854     7]\n",
      " [   21    80]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Confusion Matrix of logistic regression model -->\\n{confusion_matrix(y_test, logr_pred)}')\n",
    "print(f'Confusion Matrix of Descision tree model -->\\n{confusion_matrix(y_test, tree_pred)}')\n",
    "print(f'Confusion Matrix of Random Forest Classifier model -->\\n{confusion_matrix(y_test, ran_forest_pred)}')\n",
    "print(f'Confusion Matrix of Support Vector Classifier model -->\\n{confusion_matrix(y_test, svc_pred)}')\n",
    "print(f'Confusion Matrix of KNeighborsClassifier model -->\\n{confusion_matrix(y_test, knn_pred)}')\n",
    "print(f'Confusion Matrix of XGBClassifier model -->\\n{confusion_matrix(y_test,  xgb_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1 score = 2( (precision * recall) / (precision + recall) )**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1 score of logistic regression model -->0.7464114832535885\n",
      "  F1 score of Descision tree model -->0.8105263157894738\n",
      "  F1 score of Random Forest Classifier model -->0.7727272727272727\n",
      "  F1 score of KNeighborsClassifier model -->0.1636363636363636\n",
      "  F1 score of XGBClassifier model -->0.851063829787234\n"
     ]
    }
   ],
   "source": [
    "print(f'  F1 score of logistic regression model -->{f1_score(y_test, logr_pred)}')\n",
    "print(f'  F1 score of Descision tree model -->{f1_score(y_test, tree_pred)}')\n",
    "print(f'  F1 score of Random Forest Classifier model -->{f1_score(y_test, ran_forest_pred)}')\n",
    "print(f'  F1 score of KNeighborsClassifier model -->{f1_score(y_test, knn_pred)}')\n",
    "print(f'  F1 score of XGBClassifier model -->{f1_score(y_test,  xgb_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
